# -*- coding: utf-8 -*-
"""NLP_Practical 2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bhwNS94wQhu-FcayObkB4ocmPSQQYmKw
"""

import nltk

from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer

nltk.download('punkt')

nltk.download('stopwords')

nltk.download('wordnet')

text= "Natural Language Processing enables machines to understand human language."

import nltk

nltk.download('punkt_tab')

tokens=word_tokenize(text)

tokens

stop_words=set(stopwords.words('english'))

filtered_tokens=[word for word in tokens if word.lower() not in stop_words]

#stemming

ps=PorterStemmer()

stemmed_tokens=[ps.stem(word) for word in filtered_tokens]

lemmatizer = WordNetLemmatizer()

lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]

print("Tokens:",tokens)

print("Filtered Tokens:", filtered_tokens)

print("Stemmed Tokens:", stemmed_tokens)

print("Lemmatized Tokens:",lemmatized_tokens)