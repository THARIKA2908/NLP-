# -*- coding: utf-8 -*-
"""NLP_PRATICAL 4

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1At8b6FyvUIjYR1Ic01sZuk4y7lUWEKwT
"""

import nltk
nltk.download("punkt_tab")

from nltk.tokenize import word_tokenize
from nltk.util import ngrams
from nltk.probability import FreqDist

text = "Language modeling is an important part of Natural Language Processing."

tokens = word_tokenize(text.lower())

#General N grams (n=2)
bigrams = list(ngrams(tokens,2))

freq= FreqDist(bigrams)

print("Bigrams Frequency:")
for K, v in freq.items():
  print(K, ":", v)

print("\nMost Common Bigram:")
print(freq.most_common(5))

import nltk
nltk.download('punkt')

import nltk
from nltk.tokenize import word_tokenize
from nltk.util import ngrams
from nltk.probability import FreqDist

# download tokenizer (run once)
nltk.download('punkt')

text = "I love natural language processing and I love NLP"

# tokenize
tokens = word_tokenize(text)

# create bigrams
bigrams = list(ngrams(tokens, 2))

# frequency distribution
freq = FreqDist(bigrams)

print("Bigrams:", bigrams)
print("\nMost Common Bigrams:")
print(freq.most_common(5))

text = "Natural language processing enables machine to understand human language."

tokens = word_tokenize(text.lower())

unigrams = tokens
bigrams = list(ngrams(tokens, 2))
trigrams = list(ngrams(tokens, 3))

print("unigrams:", unigrams)
print("Bigrams:", bigrams)
print("Trigrams:",trigrams)

print("\nMost Common Unigrams:")
print(FreqDist(unigrams).most_common(5))

print("Most Comman Bigrams:")
print(FreqDist(bigrams).most_common(5))

print("Most Common Trigram:")
print(FreqDist(trigrams).most_common(5))