# -*- coding: utf-8 -*-
"""NLP_Practice

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FXD3sa_3OYBFn2_V7T3dGrk_ca3cnHMT
"""

import nltk
from nltk.stem import WordNetLemmatizer

# Download required dataset
nltk.download('wordnet')
nltk.download('omw-1.4')

# Create lemmatizer object
lemmatizer = WordNetLemmatizer()

words = ["running", "better", "cars"]
lemmas = [lemmatizer.lemmatize(w) for w in words]

print("Lemmatized words:", lemmas)

lemmatizer = WordNetLemmatizer()

word = "meeting"
lemma = lemmatizer.lemmatize(word,pos='v')
print(f"Lemmatized Word: {lemma}")

word = "flew"
lemma = lemmatizer.lemmatize(word, pos='v')

print(f"Lemmatized Word: {lemma}")

word = "drawing"
lemma = lemmatizer.lemmatize(word, pos='v')
print(f"Lemmatized Word:{lemma}")

word = "ran"
lemma = lemmatizer.lemmatize(word, pos='v')
print(f"Lemmatized Word:{lemma}")

word = "drawn"
lemma = lemmatizer.lemmatize(word, pos='v')
print(f"Lemmatized Word: {lemma}")

import nltk
from nltk.tokenize import word_tokenize
from nltk import pos_tag
nltk.download('punkt_tab')
nltk.download('averaged_perceptron_tagger_eng')

text = "NLTK is a powerful library for natural language processing."
words = word_tokenize(text)

pos_tags = pos_tag(words)

print("Original taxt:")
print(text)

print("\nPOS Tagging Result:")
for word, pos_tags in pos_tags:
  print(f"{word}: {pos_tags}")